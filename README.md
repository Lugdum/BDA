# Big Data Analytics (BDA) - TPs

Ce dépôt contient les travaux pratiques (TPs) du cours de Big Data Analytics (BDA) réalisés à EPITA. Chaque TP explore des concepts clés de l'analyse de données massives en utilisant des outils et frameworks comme Hadoop, MapReduce, et Spark.

## Contenu des TPs

### TP1 : Introduction à Hadoop et HDFS

- **Objectif** : Découvrir le système de fichiers distribué Hadoop (HDFS) et apprendre à manipuler les fichiers avec les commandes de base et une API Python.
- **Compétences** : Installation d'Hadoop, gestion des fichiers HDFS, utilisation de l'API Python pour manipuler des fichiers sur HDFS.
- [Détails du TP](./TP1/TP1.pdf)

### TP2 : Introduction à MapReduce (Partie 1)

- **Objectif** : Comprendre le paradigme de programmation MapReduce et implémenter des algorithmes simples comme le calcul de moyennes, d'histogrammes, et de WordCount en utilisant la librairie MRJob.
- **Compétences** : Calcul de statistiques via MapReduce, utilisation de MRJob pour exécuter des tâches en local et sur HDFS.
- [Détails du TP](./TP2/TP2.pdf)

### TP3 : MapReduce avancé (Partie 2)

- **Objectif** : Approfondir les concepts de MapReduce avec des exercices complexes comme la recherche d'anagrammes et le traitement de données volumineuses.
- **Compétences** : Manipulation de gros datasets, utilisation avancée de MapReduce pour l'analyse de textes, travail avec les logs de Yarn pour l'optimisation.
- [Détails du TP](./TP3/tp3.pdf)

### TP4 : Introduction à Spark et RDDs

- **Objectif** : Découvrir Apache Spark et les RDDs (Resilient Distributed Datasets), une alternative plus performante à MapReduce pour le traitement de données en mémoire.
- **Compétences** : Installation et configuration de Spark, calculs distribués en mémoire, implémentation d'algorithmes comme WordCount avec PySpark.
- [Détails du TP](./TP4/tp4.pdf)

### TP5 : PySpark et SparkSQL

- **Objectif** : Utiliser PySpark et SparkSQL pour analyser un jeu de données réel (trajets de taxi à New York) et implémenter des modèles de machine learning simples.
- **Compétences** : Nettoyage de données, analyse exploratoire avec SparkSQL, visualisation et apprentissage automatique avec MLlib.
- [Détails du TP](./TP5/tp5.pdf)

## Structure du dépôt

Chaque TP est organisé dans son propre dossier contenant les scripts, données et instructions nécessaires pour reproduire les résultats.
